#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OMNeT++ 6.1 / opp_scavetool ê²°ê³¼ í›„ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
- scavetool í•„í„° ì‚¬ìš© ì•ˆ í•¨(= Parse error íšŒí”¼)
- ì „ì²´ ë²¡í„°/ìŠ¤ì¹¼ë¼ë¥¼ CSVë¡œ ë¤í”„ í›„, Pythonì—ì„œ name/module í‚¤ì›Œë“œë¡œ í•„í„°ë§

ì¶”ì¶œ ì˜ˆì‹œ:
1) Throughput: packetReceivedFromPeer + packetBytes í¬í•¨ ë²¡í„°
2) Contention Window ë³€í™”: contentionWindowChanged í¬í•¨ ë²¡í„°
3) Retry ê´€ë ¨ ìŠ¤ì¹¼ë¼
4) Packet Loss Rate: sentPk vs packetDropRetryLimitReached

í•„ìš”í•˜ë©´ KEYWORDSë§Œ ë°”ê¾¸ë©´ ë¨.
"""

import os
import sys
import glob
import csv
import subprocess
from typing import List, Tuple

# ------------------------- ì‚¬ìš©ì ì„¤ì • -------------------------
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
OUTPUT_DIR = os.path.join(SCRIPT_DIR, 'data')

# ê²°ê³¼ íŒŒì¼(.vec/.sca) ìœ„ì¹˜ (ìš”ì²­ëŒ€ë¡œ ê³ ì •)
RESULTS_DIR = os.path.join(SCRIPT_DIR, '..', '..', 'ini', 'results')

# --- Python ì¸¡ í•„í„° í‚¤ì›Œë“œ (name/module ì»¬ëŸ¼ ê¸°ì¤€) ---
# Throughput (MAC ìˆ˜ì‹  ë°”ì´íŠ¸) í›„ë³´ í‚¤ì›Œë“œ
THR_NAME_KEYS    = ['packetReceivedFromPeer', 'packetBytes']
THR_MODULE_KEYS  = ['host[0]', 'wlan[0]', 'mac', 'dcf']   # í•„ìš”ì‹œ ì¡°ì •

# Contention Window ë³€í™”
CW_NAME_KEYS     = ['contentionWindowChanged']           # ì´ë¦„ì— ì´ ë¬¸ìì—´ í¬í•¨

# Retry, Drop, Sent ì€ ìŠ¤ì¹¼ë¼ì—ì„œ ì •í™•í•œ name ì‚¬ìš©
RETRY_NAMES      = ['packetSentToPeerWithRetry:count',
                    'packetSentToPeerWithoutRetry:count']
# UdpBasicAppì˜ ì‹¤ì œ í†µê³„ ì´ë¦„ìœ¼ë¡œ ë³€ê²½
SENT_NAME        = 'packetSent:count'
SENT_MODULE_KEY  = 'app[0]'
DROP_NAME        = 'packetDropRetryLimitReached:count'
DROP_MODULE_KEY  = 'mac.dcf'
# ---------------------------------------------------------------

def run_cmd(cmd: List[str], desc: str) -> str:
    print(f"ğŸš€ {desc}...")
    print("   $", " ".join(cmd))
    try:
        p = subprocess.run(cmd, check=True, text=True,
                           capture_output=True, encoding='utf-8')
        if p.stdout.strip():
            print(p.stdout.strip())
        print("âœ… ì™„ë£Œ\n")
        return p.stdout
    except FileNotFoundError:
        print(f"âŒ '{cmd[0]}' ëª…ë ¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. PATH ì„¤ì • í™•ì¸.")
        sys.exit(1)
    except subprocess.CalledProcessError as e:
        print(f"âŒ ì—ëŸ¬: {desc}")
        print("---- stdout ----")
        print(e.stdout)
        print("---- stderr ----")
        print(e.stderr)
        sys.exit(1)

def ensure_files() -> Tuple[List[str], List[str]]:
    vec_files = glob.glob(os.path.join(RESULTS_DIR, '*.vec'))
    sca_files = glob.glob(os.path.join(RESULTS_DIR, '*.sca'))
    if not vec_files and not sca_files:
        print(f"âŒ .vec / .sca ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ: {RESULTS_DIR}")
        sys.exit(1)
    print(f"ğŸ” vec files: {len(vec_files)}ê°œ / sca files: {len(sca_files)}ê°œ ë°œê²¬")
    return vec_files, sca_files

def dump_all(vec_files: List[str], sca_files: List[str],
             vec_out: str, sca_out: str):
    # ë²¡í„° ì „ì²´
    cmd_v = ['opp_scavetool', 'x', '-v', '-F', 'CSV-R', '-o', vec_out] + vec_files
    run_cmd(cmd_v, "ë²¡í„° ì „ì²´ ë¤í”„")

    # ìŠ¤ì¹¼ë¼ ì „ì²´
    # [ìˆ˜ì •] export ëª…ë ¹ì–´ì—ì„œëŠ” -s ì˜µì…˜ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    cmd_s = ['opp_scavetool', 'x', '-F', 'CSV-S', '-x', 'allowMixed=true', '-o', sca_out] + sca_files
    run_cmd(cmd_s, "ìŠ¤ì¹¼ë¼ ë° íŒŒë¼ë¯¸í„° ì „ì²´ ë¤í”„")

def filter_rows(in_csv: str, out_csv: str,
                name_keys: List[str] = None,
                module_keys: List[str] = None,
                name_or_keys: List[str] = None):
    """
    - name_keys: nameì— ëª¨ë‘ í¬í•¨ë˜ì–´ì•¼ í•˜ëŠ” ë¶€ë¶„ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ (AND)
    - module_keys: moduleì— ëª¨ë‘ í¬í•¨ë˜ì–´ì•¼ í•˜ëŠ” ë¶€ë¶„ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ (AND)
    - name_or_keys: nameì´ ì´ ê°’ë“¤ ì¤‘ í•˜ë‚˜ë¼ë„ 'í¬í•¨'í•´ì•¼ í•¨ (OR)
    """
    name_keys   = name_keys or []
    module_keys = module_keys or []
    name_or_keys  = name_or_keys or []

    kept = 0
    with open(in_csv, newline='', encoding='utf-8') as fi, \
         open(out_csv, 'w', newline='', encoding='utf-8') as fo:
        reader = csv.DictReader(fi)
        if not reader.fieldnames:
            return
        writer = csv.DictWriter(fo, fieldnames=reader.fieldnames)
        writer.writeheader()

        for row in reader:
            name_val   = row.get('name', '')
            module_val = row.get('module', '')

            if name_or_keys:
                if not any(k in name_val for k in name_or_keys):
                    continue

            if name_keys and not all(k in name_val for k in name_keys):
                continue
            if module_keys and not all(k in module_val for k in module_keys):
                continue

            writer.writerow(row)
            kept += 1

    print(f"â„¹ï¸  {os.path.basename(out_csv)}: {kept} rows kept "
          f"(name_keys={name_keys}, module_keys={module_keys}, name_or_keys={name_or_keys})")

def sum_scalar(csv_path: str, name_target: str, module_key: str = None) -> float:
    """CSV íŒŒì¼ì—ì„œ íŠ¹ì • ìŠ¤ì¹¼ë¼ ê°’ë“¤ì„ í•©ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    total = 0.0
    with open(csv_path, newline='', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            if name_target in row.get('name', ''):
                if module_key and module_key not in row.get('module', ''):
                    continue
                try:
                    total += float(row.get('value', '0'))
                except (ValueError, TypeError):
                    pass
    return total

def main():
    print("--- OMNeT++ ê²°ê³¼ ë°ì´í„° í›„ì²˜ë¦¬ ì‹œì‘ ---")
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥: {OUTPUT_DIR}\n")

    vec_files, sca_files = ensure_files()

    # 1) ì „ì²´ ë¤í”„
    all_vec_csv = os.path.join(OUTPUT_DIR, 'all_vectors.csv')
    all_sca_csv = os.path.join(OUTPUT_DIR, 'all_scalars.csv')
    dump_all(vec_files, sca_files, all_vec_csv, all_sca_csv)

    # 2) Throughput ë²¡í„° ì¶”ì¶œ
    thr_csv = os.path.join(OUTPUT_DIR, 'throughput.csv')
    filter_rows(all_vec_csv, thr_csv,
                name_keys=THR_NAME_KEYS,
                module_keys=THR_MODULE_KEYS)

    # 3) CW ë²¡í„° ì¶”ì¶œ
    cw_csv = os.path.join(OUTPUT_DIR, 'cw_data.csv')
    filter_rows(all_vec_csv, cw_csv,
                name_keys=CW_NAME_KEYS)

    # 4) Retry ìŠ¤ì¹¼ë¼ ì¶”ì¶œ
    retry_csv = os.path.join(OUTPUT_DIR, 'retry_counts.csv')
    filter_rows(all_sca_csv, retry_csv,
                name_or_keys=RETRY_NAMES)

    # 5) Packet Loss Rate ê³„ì‚°
    total_sent    = sum_scalar(all_sca_csv, SENT_NAME, module_key=SENT_MODULE_KEY)
    total_dropped = sum_scalar(all_sca_csv, DROP_NAME, module_key=DROP_MODULE_KEY)
    loss_rate = (total_dropped / total_sent * 100.0) if total_sent > 0 else 0.0

    summary = (
        "----- ìš”ì•½ -----\n"
        f"- ì´ ì „ì†¡ íŒ¨í‚·(sentPk): {total_sent:.0f}\n"
        f"- ì¬ì‹œë„ í•œê³„ ë“œë(packetDropRetryLimitReached): {total_dropped:.0f}\n"
        f"- íŒ¨í‚· ì†ì‹¤ë¥ : {loss_rate:.2f}%\n"
    )
    print(summary)

    summary_file = os.path.join(OUTPUT_DIR, 'packet_loss_summary.txt')
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(summary.strip())

    print(f"âœ… ìš”ì•½ ì €ì¥: {summary_file}")
    print("\n--- ëª¨ë“  í›„ì²˜ë¦¬ ì‘ì—… ì™„ë£Œ ---")

if __name__ == "__main__":
    main()
